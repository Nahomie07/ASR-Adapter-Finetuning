import os
import json
import requests
from tqdm.auto import tqdm
import argparse

"""
====================================================
   BUILD MINI DATASET FOR KAGGLE (DOCUMENTED)
====================================================

Ce script permet de crÃ©er un jeu de donnÃ©es local Ã  
partir du dataset ASR Fellowship Challenge *sans*
tÃ©lÃ©charger les ~57 Go du dataset complet.

Il tÃ©lÃ©charge uniquement les N premiÃ¨res lignes du 
fichier metadata.jsonl + les fichiers audio associÃ©s.

Structure gÃ©nÃ©rÃ©e :
    data/
      â”œâ”€â”€ metadata.jsonl
      â””â”€â”€ audio/
            â”œâ”€â”€ xxxx.wav
            â”œâ”€â”€ yyyy.wav

Ce dataset local est compatible avec le train.py corrigÃ© 
et n'utilise qu'une fraction de l'espace disque Kaggle.
"""


def download_metadata(index_url, n):
    """
    TÃ©lÃ©charge uniquement les N premiÃ¨res lignes du metadata.jsonl
    depuis HuggingFace, sans tÃ©lÃ©charger tout le dataset.
    """
    print(f"ğŸ“¥ TÃ©lÃ©chargement des {n} entrÃ©es metadata...")

    samples = []
    with requests.get(index_url, stream=True) as r:
        for line in r.iter_lines():
            if line:
                sample = json.loads(line)
                samples.append(sample)

                if len(samples) >= n:
                    break
    return samples


def download_audio(samples, audio_dir):
    """
    TÃ©lÃ©charge les fichiers audio correspondant aux Ã©chantillons.
    """
    print("ğŸ§ TÃ©lÃ©chargement des fichiers audio...")

    os.makedirs(audio_dir, exist_ok=True)

    for s in tqdm(samples):
        url = s["audio"]["path"]
        local_name = os.path.basename(url)
        out_path = os.path.join(audio_dir, local_name)

        # Skip si dÃ©jÃ  tÃ©lÃ©chargÃ©
        if os.path.exists(out_path):
            continue

        r = requests.get(url, stream=True)
        with open(out_path, "wb") as f:
            for chunk in r.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)

        # Remplace le chemin HF par le chemin local
        s["audio"]["path"] = out_path

    return samples


def save_metadata(samples, output_path):
    """
    Enregistre les mÃ©tadonnÃ©es finales (avec chemins audio locaux).
    """
    with open(output_path, "w", encoding="utf-8") as f:
        for s in samples:
            f.write(json.dumps(s, ensure_ascii=False) + "\n")

    print("ğŸ“„ metadata.jsonl enregistrÃ© :", output_path)


def main(args):
    # URLs officielles du dataset DigitalUmuganda
    index_url = (
        "https://huggingface.co/datasets/DigitalUmuganda/"
        "ASR_Fellowship_Challenge_Dataset/resolve/main/data/train/metadata.jsonl"
    )

    data_dir = args.data_dir
    audio_dir = os.path.join(data_dir, "audio")
    os.makedirs(data_dir, exist_ok=True)

    # Ã‰tape 1 : TÃ©lÃ©charger N lignes du metadata.jsonl
    samples = download_metadata(index_url, args.n)

    # Ã‰tape 2 : TÃ©lÃ©charger seulement les audios correspondants
    samples = download_audio(samples, audio_dir)

    # Ã‰tape 3 : Sauvegarder metadata.jsonl local
    metadata_path = os.path.join(data_dir, "metadata.jsonl")
    save_metadata(samples, metadata_path)

    print("âœ… Mini dataset complet et prÃªt pour l'entraÃ®nement !")
    print(f"ğŸ“ Dossier : {data_dir}")
    print(f"ğŸ“¦ Nombre d'Ã©chantillons : {len(samples)}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--n", type=int, default=300,
                        help="Nombre d'Ã©chantillons Ã  tÃ©lÃ©charger (dÃ©faut=300)")
    parser.add_argument("--data_dir", default="data",
                        help="Dossier de sortie du dataset local")
    args = parser.parse_args()
    main(args)
